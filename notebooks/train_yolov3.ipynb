{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training YOLOv3-tiny on Custom Dataset\n",
    "\n",
    "This notebook will guide you through the process of training a YOLOv3-tiny model on your custom dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Prerequisites\n",
    "\n",
    "First, we'll use the provided setup script to compile Darknet. We need to ensure we're in the correct directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Navigate to the project root directory\n",
    "os.chdir('..')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if darknet directory exists\n",
    "if not os.path.exists('darknet'):\n",
    "    print(\"Darknet directory not found. Setting up Darknet...\")\n",
    "    # Make the script executable\n",
    "    subprocess.run(['chmod', '+x', 'setup_darknet.sh'])\n",
    "    # Run the setup script\n",
    "    subprocess.run(['./setup_darknet.sh'])\n",
    "else:\n",
    "    print(\"Darknet directory already exists. Skipping setup.\")\n",
    "\n",
    "# Navigate back to the notebooks directory\n",
    "os.chdir('notebooks')\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = \"/home/akash/My_Projects/Optical-Plant-Identification-for-Farming-Vehicles-\"\n",
    "DARKNET_PATH = os.path.join(PROJECT_ROOT, \"darknet\")\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"processed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Training and Validation Lists\n",
    "\n",
    "create two files: `train.txt`, `valid.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_list_file(set_type):\n",
    "    image_dir = os.path.join(DATA_PATH, set_type, \"images\")\n",
    "    label_dir = os.path.join(DATA_PATH, set_type, \"labels\")\n",
    "    output_file = os.path.join(DARKNET_PATH, \"data\", f\"{set_type}.txt\")\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        for image in os.listdir(image_dir):\n",
    "            if image.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.abspath(os.path.join(image_dir, image))\n",
    "                label_path = os.path.abspath(os.path.join(label_dir, os.path.splitext(image)[0] + '.txt'))\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    f.write(f\"{image_path} {label_path}\\n\")\n",
    "                else:\n",
    "                    print(f\"Warning: No label file for {image}\")\n",
    "    \n",
    "    print(f\"Created {output_file}\")\n",
    "\n",
    "# Create train.txt and val.txt\n",
    "create_yolo_list_file(\"augmented_train\")\n",
    "create_yolo_list_file(\"val\")\n",
    "\n",
    "# Read and print class names\n",
    "classes_file = os.path.join(DATA_PATH, 'augmented_train', 'labels', 'classes.txt')\n",
    "if os.path.exists(classes_file):\n",
    "    with open(classes_file, 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "    print(f\"Classes found: {classes}\")\n",
    "else:\n",
    "    print(\"Warning: classes.txt file not found in the expected location.\")\n",
    "\n",
    "print(\"Data file creation completed. Please verify the contents of the created files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Configuration Files\n",
    "\n",
    "We need to create three files: `obj.names`, `obj.data`, and `yolov3-tiny.cfg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create obj.names\n",
    "with open(os.path.join(DARKNET_PATH, \"data\", \"obj.names\"), \"w\") as f:\n",
    "    f.write(\"rumex_acetosa\\n\")\n",
    "\n",
    "# Create obj.data\n",
    "obj_data_content = f\"\"\"classes = 1\n",
    "train = data/augmented_train.txt\n",
    "valid = data/val.txt\n",
    "names = data/obj.names\n",
    "backup = backup/\n",
    "\"\"\"\n",
    "with open(os.path.join(DARKNET_PATH, \"data\", \"obj.data\"), \"w\") as f:\n",
    "    f.write(obj_data_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and print yolov3-tiny.cfg\n",
    "!cp ../darknet/cfg/yolov3-tiny.cfg ../darknet/cfg/yolov3-tiny-obj.cfg\n",
    "\n",
    "print(\"Original configuration:\")\n",
    "!head -n 20 ../darknet/cfg/yolov3-tiny-obj.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = os.path.join(DARKNET_PATH, \"cfg\", \"yolov3-tiny-obj.cfg\")\n",
    "\n",
    "# Modify yolov3-tiny-obj.cfg\n",
    "!sed -i 's/# Training/Training/' {cfg_path}\n",
    "!sed -i 's/batch=1/# batch=1/' {cfg_path}\n",
    "!sed -i 's/subdivisions=1/# subdivisions=1/' {cfg_path}\n",
    "!sed -i 's/# batch=64/batch=32/' {cfg_path}\n",
    "!sed -i 's/# subdivisions=2/subdivisions=32/' {cfg_path}\n",
    "!sed -i 's/width=416/width=416/' {cfg_path}\n",
    "!sed -i 's/height=416/height=416/' {cfg_path}\n",
    "!sed -i 's/max_batches = 500200/max_batches = 2000/' {cfg_path}\n",
    "!sed -i 's/learning_rate=0.001/learning_rate=0.001/' {cfg_path}\n",
    "!sed -i '/steps=/ c\\steps=1600,1800' {cfg_path}\n",
    "!sed -i 's/classes=80/classes=1/g' {cfg_path}\n",
    "!sed -i 's/filters=255/filters=18/g' {cfg_path}\n",
    "\n",
    "print(\"Updated configuration:\")\n",
    "!head -n 20 {cfg_path}\n",
    "\n",
    "print(\"\\nYOLO layer changes:\")\n",
    "!grep -A 3 \"\\[yolo\\]\" {cfg_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Pre-trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Define the weights file path\n",
    "weights_path = os.path.join(DARKNET_PATH, 'yolov3-tiny.weights')\n",
    "\n",
    "# Check if weights file exists\n",
    "if not os.path.exists(weights_path):\n",
    "    print(\"Downloading YOLOv3-tiny weights...\")\n",
    "    weights_url = 'https://pjreddie.com/media/files/yolov3-tiny.weights'\n",
    "    urllib.request.urlretrieve(weights_url, weights_path)\n",
    "    print(\"Weights downloaded successfully.\")\n",
    "else:\n",
    "    print(\"YOLOv3-tiny weights file already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!cd ../darknet && ./darknet detector train data/obj.data cfg/yolov3-tiny-obj.cfg yolov3-tiny.weights -dont_show -map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the Trained Model\n",
    "\n",
    "Once training is complete, you can test your model on new images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../darknet && ./darknet detector test data/obj.data cfg/yolov3-tiny-obj.cfg backup/yolov3-tiny-obj_final.weights path_to_test_image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "\n",
    "def check_random_images(data_file, num_images=5):\n",
    "    with open(data_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    sample = random.sample(lines, min(num_images, len(lines)))\n",
    "    \n",
    "    for line in sample:\n",
    "        image_path, _ = line.strip().split()\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "        else:\n",
    "            print(f\"Successfully loaded image: {image_path}, Shape: {img.shape}\")\n",
    "\n",
    "print(\"Checking random training images:\")\n",
    "check_random_images(os.path.join(DARKNET_PATH, \"data\", \"augmented_train.txt\"))\n",
    "\n",
    "print(\"\\nChecking random validation images:\")\n",
    "check_random_images(os.path.join(DARKNET_PATH, \"data\", \"val.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_file_paths(list_file):\n",
    "    with open(list_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        image_path, label_path = line.strip().split()\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Label not found: {label_path}\")\n",
    "\n",
    "print(\"Checking training file paths:\")\n",
    "check_file_paths(os.path.join(DARKNET_PATH, \"data\", \"augmented_train.txt\"))\n",
    "\n",
    "print(\"\\nChecking validation file paths:\")\n",
    "check_file_paths(os.path.join(DARKNET_PATH, \"data\", \"val.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_file_head(file_path, num_lines=5):\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i < num_lines:\n",
    "                print(line.strip())\n",
    "            else:\n",
    "                break\n",
    "\n",
    "print(\"First 5 lines of training list file:\")\n",
    "print_file_head(os.path.join(DARKNET_PATH, \"data\", \"augmented_train.txt\"))\n",
    "\n",
    "print(\"\\nFirst 5 lines of validation list file:\")\n",
    "print_file_head(os.path.join(DARKNET_PATH, \"data\", \"val.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Content of obj.data file:\")\n",
    "with open(os.path.join(DARKNET_PATH, \"data\", \"obj.data\"), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_yolo_layers(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('[yolo]'):\n",
    "            print(f\"YOLO layer found at line {i+1}:\")\n",
    "            for j in range(i, min(i+10, len(lines))):\n",
    "                print(lines[j].strip())\n",
    "            print()\n",
    "\n",
    "print(\"YOLO layers in the configuration file:\")\n",
    "print_yolo_layers(os.path.join(DARKNET_PATH, \"cfg\", \"yolov3-tiny-obj.cfg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def check_random_labels(data_file, num_labels=5):\n",
    "    with open(data_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    sample = random.sample(lines, min(num_labels, len(lines)))\n",
    "    \n",
    "    for line in sample:\n",
    "        _, label_path = line.strip().split()\n",
    "        print(f\"Content of {label_path}:\")\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            print(label_file.read())\n",
    "        print()\n",
    "\n",
    "print(\"Checking random training labels:\")\n",
    "check_random_labels(os.path.join(DARKNET_PATH, \"data\", \"augmented_train.txt\"))\n",
    "\n",
    "print(\"\\nChecking random validation labels:\")\n",
    "check_random_labels(os.path.join(DARKNET_PATH, \"data\", \"val.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Content of obj.names file:\")\n",
    "with open(os.path.join(DARKNET_PATH, \"data\", \"obj.names\"), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def check_random_image_dimensions(data_file, num_images=5):\n",
    "    with open(data_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    sample = random.sample(lines, min(num_images, len(lines)))\n",
    "    \n",
    "    for line in sample:\n",
    "        image_path, _ = line.strip().split()\n",
    "        img = cv2.imread(image_path)\n",
    "        print(f\"Image: {image_path}\")\n",
    "        print(f\"Dimensions: {img.shape}\")\n",
    "        print(f\"Data type: {img.dtype}\")\n",
    "        print()\n",
    "\n",
    "print(\"Checking random training image dimensions:\")\n",
    "check_random_image_dimensions(os.path.join(DARKNET_PATH, \"data\", \"augmented_train.txt\"))\n",
    "\n",
    "print(\"\\nChecking random validation image dimensions:\")\n",
    "check_random_image_dimensions(os.path.join(DARKNET_PATH, \"data\", \"val.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
